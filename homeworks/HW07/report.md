# HW07 – Report

> Файл: `homeworks/HW07/report.md`  


## 1. Datasets

3 датасета:

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (1200, 9)
- Признаки: все числовые
- Пропуски: нет
- "Подлости" датасета: разные шкалы, шум

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: все числовые
- Пропуски: нет
- "Подлости" датасета: нелинейная структура, шумовой признак, выбросы

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5)
- Признаки: все числовые
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности, 

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: scaling, pca
- Поиск гиперпараметров:
  - k подбирался от 2 до 20
  - eps  от 0.5 до 5. Диапазон вариировался от датасета.
  - min_samples от 2 до 10. Диапазон вариировался от датасета
  - чем руководствовались при выборе "лучшего"
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz. Для dbscan метрики считались на non-noise точках
- Визуализация: PCA(2D). В figures/ для каждого датасета

## 3. Models

### 3.2 Dataset A

- KMeans (поиск `k` - от 2 до 20, фиксировали `random_state` = 42, `n_init` = 'auto')
  - DBSCAN (`eps`: [1.0, 2.5, 3.0, 3.5, 4.0], `min_samples`: [2, 6, 10] , доля шума: [0.0; 0.001])

### 3.2 Dataset B

- KMeans (поиск `k` - от 2 до 20, фиксировали `random_state` = 42, `n_init` = 'auto')
  - DBSCAN (`eps`: [0.5, 1.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0], `min_samples`: [2, 4, 6, 8, 10] , доля шума: [-0.77; 0.064]  )

### 3.3 Dataset C

- KMeans (поиск `k` - от 2 до 20, фиксировали `random_state` = 42, `n_init` = 'auto')
  - DBSCAN (`eps`: [0.2, 0.3, 0.5, 1.0, 1.5, 2.5], `min_samples`: [2, 4, 6, 8, 10] , доля шума: [-0.266; 0.27])

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: (k= 5, random_state = 42, n_init )
- Метрики (silhouette / DB / CH):
     - "silhouette": 0.3573010393270957,
     - "davies_bouldin": 1.2431101963239783,
     - "calinski_harabasz": 8554.6196254245
- Это решение выглядит разумно, поскольку кластеры имеют шарообразную форму. Алгоритм kmeans хорошо работает с подобными данными.

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN ('eps': 0.5, 'min_samples': 10, n_clusters: 2)
- Метрики (silhouette / DB / CH):
	- silhouette: 0.251
  	- davies_bouldin: 0.742
  	- calinski_harabasz: 26.2
- Если был DBSCAN: noise_frac: 0.064,  non-noise: 7491
- Это решение выглядит разумно, поскольку кластеры имеют неправильную форму. В данных много шума.

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN ('eps': 0.3, 'min_samples': 10, )
- Метрики (silhouette / DB / CH):
	- silhouette: 0.204
  	- davies_bouldin: 1.131
  	- calinski_harabasz: 2255.9
- Если был DBSCAN: n_clusters: 3
- Это решение выглядит разумно, поскольку у кластеров неправильная форма, выбросы в данных, шум.


## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?
	- при разной плотности кластеров, неправильной форме, при наличии выбросов, при неправильном количестве кластеров.
- Где DBSCAN/иерархическая кластеризация выигрывают и почему?
	- при наличии шума/выбросов, неправильной форме кластеров. DBSCAN определяет количество кластеров на основе локальной плотности, что делает его более гибким в исследовательском анализе.
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?
	- Масштабирование признаков, выбросы, плотность кластеров.

### 5.2 Устойчивость (обязательно для одного датасета)

- Для оценки устойчивости алгоритма KMeans было выполнено 5 независимых запусков с разными значениями random_state (сгенерированными из фиксированного seed). Согласованность между парами полученных разметок оценивалась с помощью ARI. Для первого датасета проводилась проверка.
- Средний ARI по всем парам составил 0.68, что указывает на умеренную согласованность результатов: разбиения близки, но не идентичны.
- Вывод: кластеризация методом KMeans в данном случае в целом устойчива, но не полностью детерминирована. Значение ARI = 0.68 говорит о том, что структура данных, вероятно, содержит достаточно чёткие компактные группы

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - по среднему



## 6. Conclusion

- Кластеризация — не «автоматическая» задача: выбор алгоритма (KMeans, DBSCAN и др.) должен основываться на структуре данных (форма, плотность, шум), а не на удобстве.
- Нет «истинной» метки в unsupervised-обучении, поэтому оценка качества требует нескольких метрик (silhouette, Davies–Bouldin, Calinski–Harabasz) и визуального анализа (PCA/t-SNE).
- Предобработка критична: масштабирование обязательно для всех методов, а пропуски и категориальные признаки требуют отдельной обработки.
- DBSCAN устойчив к выбросам и не требует задавать число кластеров.
- Надёжный unsupervised-эксперимент требует проверки устойчивости (например, через ARI при разных random_state) и честного сравнения нескольких алгоритмов на единой предобработке.

